{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e830e94d-9e1f-4c42-b6b6-b39254f500a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Import the required libraries for file upload\n",
    "from ipywidgets import FileUpload\n",
    "import io\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce4f9d-e01b-4294-944c-1097f1cf4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file upload widgets for both images\n",
    "ref_upload_widget = FileUpload(accept='.jpg', description='Upload Reference Form')\n",
    "scanned_upload_widget = FileUpload(accept='.jpg', description='Upload Scanned Form')\n",
    "\n",
    "# Display the file upload widgets\n",
    "display(ref_upload_widget, scanned_upload_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5729948d-9778-4066-b5f0-d74046d34dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read the uploaded files\n",
    "def read_uploaded_images(ref_uploaded_files, scanned_uploaded_files):\n",
    "    # Check if both files are uploaded\n",
    "    if len(ref_uploaded_files) != 1 or len(scanned_uploaded_files) != 1:\n",
    "        print(\"Please upload one reference form and one scanned form.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Unpack the tuple to get file data\n",
    "    ref_uploaded_file = ref_uploaded_files[0]\n",
    "    scanned_uploaded_file = scanned_uploaded_files[0]\n",
    "    \n",
    "    # Read the reference form image\n",
    "    ref_filename = ref_uploaded_file.name\n",
    "    ref_file_data = ref_uploaded_file['content']\n",
    "    ref_nparr = np.frombuffer(ref_file_data, np.uint8)\n",
    "    ref_image = cv2.imdecode(ref_nparr, cv2.IMREAD_COLOR)\n",
    "    ref_image = cv2.cvtColor(ref_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Read the scanned form image\n",
    "    scanned_filename = scanned_uploaded_file.name\n",
    "    scanned_file_data = scanned_uploaded_file['content']\n",
    "    scanned_nparr = np.frombuffer(scanned_file_data, np.uint8)\n",
    "    scanned_image = cv2.imdecode(scanned_nparr, cv2.IMREAD_COLOR)\n",
    "    scanned_image = cv2.cvtColor(scanned_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return ref_image, scanned_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c079b2-b8df-4b31-98d3-4a24c8cf5b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process and display images\n",
    "def process_images(_):\n",
    "    # Get the uploaded file data for the reference form and scanned form\n",
    "    ref_uploaded_files = ref_upload_widget.value\n",
    "    scanned_uploaded_files = scanned_upload_widget.value\n",
    "    \n",
    "    # Read the uploaded images\n",
    "    ref_image, scanned_image = read_uploaded_images(ref_uploaded_files, scanned_uploaded_files)\n",
    "    \n",
    "    if ref_image is not None and scanned_image is not None:\n",
    "        # Convert images to grayscale\n",
    "        ref_gray = cv2.cvtColor(ref_image, cv2.COLOR_RGB2GRAY)\n",
    "        scanned_gray = cv2.cvtColor(scanned_image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Detect ORB features and compute descriptors with an increased number of features\n",
    "        MAX_NUM_FEATURES = 10000  # Increase the number of features\n",
    "        orb = cv2.ORB_create(MAX_NUM_FEATURES)\n",
    "        keypoints1, descriptors1 = orb.detectAndCompute(ref_gray, None)\n",
    "        keypoints2, descriptors2 = orb.detectAndCompute(scanned_gray, None)\n",
    "        \n",
    "        # Match features\n",
    "        matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "        matches = list(matcher.match(descriptors1, descriptors2, None))\n",
    "        \n",
    "        # Sort matches by score\n",
    "        matches.sort(key=lambda x: x.distance, reverse=False)\n",
    "        \n",
    "        # Remove not-so-good matches\n",
    "        numGoodMatches = int(len(matches) * 0.5)\n",
    "        matches = matches[:numGoodMatches]\n",
    "        \n",
    "        # Calculate and display the percentage and number of feature matches\n",
    "        total_matches = len(matches)\n",
    "        total_keypoints1 = len(keypoints1)\n",
    "        total_keypoints2 = len(keypoints2)\n",
    "        match_percentage = (total_matches / min(total_keypoints1, total_keypoints2)) * 100\n",
    "        \n",
    "        print(f\"Number of feature matches: {total_matches}\")\n",
    "        print(f\"Percentage of feature matches: {match_percentage:.2f}%\")\n",
    "        \n",
    "        # Extract location of good matches\n",
    "        points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "        points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "        \n",
    "        for i, match in enumerate(matches):\n",
    "            points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "            points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "        \n",
    "        # Find homography\n",
    "        h, mask = cv2.findHomography(points2, points1, cv2.RANSAC)\n",
    "        \n",
    "        # Use homography to warp image\n",
    "        height, width, channels = ref_image.shape\n",
    "        scanned_image_aligned = cv2.warpPerspective(scanned_image, h, (width, height))\n",
    "        \n",
    "        # Display the original form and scanned form images\n",
    "        plt.figure(figsize=[20, 10])\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(ref_image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Reference Form (Uploaded)\")\n",
    "        \n",
    "        plt.subplot(132)\n",
    "        plt.imshow(scanned_image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Scanned Form (Uploaded)\")\n",
    "        \n",
    "        plt.subplot(133)\n",
    "        plt.imshow(scanned_image_aligned)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Aligned Scanned Form\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ef92a3-60cc-4918-94e1-8ba35dfe04ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process uploaded images when a button is clicked\n",
    "from ipywidgets import Button\n",
    "\n",
    "process_button = Button(description=\"Process Images\")\n",
    "\n",
    "# Attach the process_images function to the button's click event\n",
    "process_button.on_click(process_images)\n",
    "\n",
    "# Display the process button\n",
    "display(process_button)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
